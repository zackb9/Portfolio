{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.seasonal import DecomposeResult\n",
    "\n",
    "register_matplotlib_converters()\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.rc(\"figure\", figsize=(16, 12))\n",
    "plt.rc(\"font\", size=13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('./data/shop_1_transactions.csv',sep=';')\n",
    "df1['date'] = pd.to_datetime(df1['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_ts(df, number_of_items=15):\n",
    "    \"\"\"\n",
    "    Extract daily time series from the data \n",
    "    \"\"\"\n",
    "    # get the list of the 10 most popular items\n",
    "    popular_item_ids = df.groupby(\n",
    "        ['item_id'])['quantity'].sum().sort_values(ascending=False).index\n",
    "\n",
    "    result = {}\n",
    "    for k in range(number_of_items):\n",
    "        # load the sales of the most popular item\n",
    "        item_df = df[df['item_id'] == popular_item_ids[k]]\n",
    "\n",
    "        # remove outlierz with the zscore method\n",
    "        item_df = item_df[np.abs(zscore(item_df['quantity'])) < 2]\n",
    "\n",
    "        # get the data grouped by day\n",
    "        ts = item_df.set_index('date').resample('D')[['quantity']].sum()\n",
    "        result[popular_item_ids[k]] = ts\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def split_groupped_data_to_slices(df, time_steps, input_cols, target_col, time_col, id_col):\n",
    "    \"\"\"\n",
    "    Split the data in a fixed window size to feed model with fixed input size.\n",
    "    \"\"\"\n",
    "    # Calculate the total number of entries in the DataFrame\n",
    "    num_entries = len(df)\n",
    "\n",
    "    # Calculate the valid starting indices for each slice\n",
    "    valid_sampling_locations = [time_steps +\n",
    "                                i for i in range(num_entries - time_steps + 1)]\n",
    "\n",
    "    # Initialize empty lists for inputs, outputs, time information, and identifiers\n",
    "    inputs_list, outputs_list, time_list, identifiers_list = [], [], [], []\n",
    "\n",
    "    # Loop over each valid starting index and extract relevant information for each slice\n",
    "    for start_idx in valid_sampling_locations:\n",
    "        # Slice the DataFrame to extract the relevant rows\n",
    "        sliced = df.iloc[start_idx - time_steps:start_idx]\n",
    "\n",
    "        # Extract inputs, outputs, time information, and identifiers from the sliced DataFrame\n",
    "        inputs = sliced[input_cols].to_numpy()\n",
    "        outputs = sliced[[target_col]].to_numpy()\n",
    "        time = sliced[time_col].to_numpy()\n",
    "        identifiers = sliced[id_col].to_numpy()\n",
    "\n",
    "        # Append the extracted information to the appropriate list\n",
    "        inputs_list.append(inputs)\n",
    "        outputs_list.append(outputs)\n",
    "        time_list.append(time)\n",
    "        identifiers_list.append(identifiers)\n",
    "\n",
    "    # Return a tuple containing the four lists of extracted information\n",
    "    return inputs_list, outputs_list, time_list, identifiers_list\n",
    "\n",
    "\n",
    "def numpy_normalised_quantile_loss(y, y_pred, quantile):\n",
    "    \"\"\"Computes normalised quantile loss for numpy arrays.\n",
    "    Uses the q-Risk metric as defined in the \"Training Procedure\" section of the\n",
    "    main TFT paper.\n",
    "    Args:\n",
    "      y: Targets\n",
    "      y_pred: Predictions\n",
    "      quantile: Quantile to use for loss calculations (between 0 & 1)\n",
    "    Returns:\n",
    "      Float for normalised quantile loss.\n",
    "    \"\"\"\n",
    "    prediction_underflow = y - y_pred\n",
    "    weighted_errors = quantile * np.maximum(prediction_underflow, 0.) \\\n",
    "        + (1. - quantile) * np.maximum(-prediction_underflow, 0.)\n",
    "\n",
    "    quantile_loss = weighted_errors.mean()\n",
    "    normaliser = y.abs().mean()\n",
    "\n",
    "    return 2 * quantile_loss / normaliser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calendar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def get_calendar_data():\n",
    "    # request the json file with all of the calendar events in France\n",
    "    res = requests.get('https://calendrier.api.gouv.fr/jours-feries/metropole.json')\n",
    "\n",
    "    # convert the data to a dataframe\n",
    "    df = pd.DataFrame.from_dict(res.json(),orient='index')\n",
    "    df.columns = ['calendar_event']\n",
    "\n",
    "    # parse the date index\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    # resample by day and fill the missing values\n",
    "    df = df.resample('D').first().fillna(\"\")\n",
    "\n",
    "    # use the label encoder to convert to numerical values. \n",
    "    le = LabelEncoder()\n",
    "    le.fit(df['calendar_event'])\n",
    "    df['calendar_embedding'] = le.transform(df['calendar_event'])\n",
    "    \n",
    "    # return also the label encoder for parsing\n",
    "    return df, le\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calendar_event</th>\n",
       "      <th>calendar_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-01-01</th>\n",
       "      <td>1er janvier</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-04-21</th>\n",
       "      <td>Lundi de Pâques</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-05-01</th>\n",
       "      <td>1er mai</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-05-08</th>\n",
       "      <td>8 mai</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-05-29</th>\n",
       "      <td>Ascension</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028-07-14</th>\n",
       "      <td>14 juillet</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028-08-15</th>\n",
       "      <td>Assomption</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028-11-01</th>\n",
       "      <td>Toussaint</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028-11-11</th>\n",
       "      <td>11 novembre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028-12-25</th>\n",
       "      <td>Jour de Noël</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             calendar_event  calendar_embedding\n",
       "2003-01-01      1er janvier                   3\n",
       "2003-04-21  Lundi de Pâques                  10\n",
       "2003-05-01          1er mai                   4\n",
       "2003-05-08            8 mai                   5\n",
       "2003-05-29        Ascension                   6\n",
       "...                     ...                 ...\n",
       "2028-07-14       14 juillet                   2\n",
       "2028-08-15       Assomption                   7\n",
       "2028-11-01        Toussaint                  11\n",
       "2028-11-11      11 novembre                   1\n",
       "2028-12-25     Jour de Noël                   8\n",
       "\n",
       "[285 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_calendar_data()[0][get_calendar_data()[0]['calendar_embedding'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>temp_avg</th>\n",
       "      <th>rain</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind</th>\n",
       "      <th>cloud_cov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>91</td>\n",
       "      <td>9</td>\n",
       "      <td>46.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>-4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>97</td>\n",
       "      <td>13</td>\n",
       "      <td>32.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-04</td>\n",
       "      <td>-4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91</td>\n",
       "      <td>19</td>\n",
       "      <td>53.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>98</td>\n",
       "      <td>28</td>\n",
       "      <td>98.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5228</th>\n",
       "      <td>2023-04-26</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74</td>\n",
       "      <td>9</td>\n",
       "      <td>47.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5229</th>\n",
       "      <td>2023-04-27</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>87</td>\n",
       "      <td>13</td>\n",
       "      <td>67.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5230</th>\n",
       "      <td>2023-04-28</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97</td>\n",
       "      <td>22</td>\n",
       "      <td>83.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5231</th>\n",
       "      <td>2023-04-29</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88</td>\n",
       "      <td>9</td>\n",
       "      <td>42.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5232</th>\n",
       "      <td>2023-04-30</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83</td>\n",
       "      <td>10</td>\n",
       "      <td>59.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5233 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  temp_min  temp_max  temp_avg  rain  humidity  wind  cloud_cov\n",
       "0    2009-01-01        -5         1         1   0.0        90    10     12.000\n",
       "1    2009-01-02        -5         1         0   0.1        91     9     46.000\n",
       "2    2009-01-03        -4         1         1   0.1        97    13     32.625\n",
       "3    2009-01-04        -4         1         1   0.0        91    19     53.125\n",
       "4    2009-01-05        -1         0         0   6.0        98    28     98.250\n",
       "...         ...       ...       ...       ...   ...       ...   ...        ...\n",
       "5228 2023-04-26         3        12        10   0.0        74     9     47.750\n",
       "5229 2023-04-27         8        18        16   0.2        87    13     67.625\n",
       "5230 2023-04-28        13        18        16   1.0        97    22     83.875\n",
       "5231 2023-04-29         9        17        16   0.0        88     9     42.500\n",
       "5232 2023-04-30         9        16        15   0.0        83    10     59.250\n",
       "\n",
       "[5233 rows x 8 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_weather_file(filename):\n",
    "    # Define the key_mapper dictionary\n",
    "    key_mapper = {\n",
    "        \"DATE\": 'date',\n",
    "        \"MIN_TEMPERATURE_C\": 'temp_min', # minimum temperature in degrees Celsius.\n",
    "        \"MAX_TEMPERATURE_C\": 'temp_max', # maximum temperature in degrees Celsius.\n",
    "        \"TEMPERATURE_NOON_C\": 'temp_avg', #  the temperature at noon in degrees Celsius.\n",
    "        \"PRECIP_TOTAL_DAY_MM\": 'rain', # total precipitation for the day in millimeters.\n",
    "        \"HUMIDITY_MAX_PERCENT\": 'humidity', # the maximum humidity for the day as a percentage.\n",
    "        \"WINDSPEED_MAX_KMH\": 'wind', # maximum wind speed for the day in kilometers per hour.\n",
    "        \"CLOUDCOVER_AVG_PERCENT\": 'cloud_cov' # the average cloud cover for the day as a percentage.\n",
    "    }\n",
    "\n",
    "    # Read the csv file and map the column names\n",
    "    df = pd.read_csv(filename,sep=',')\n",
    "    df = df.rename(columns=key_mapper)\n",
    "\n",
    "    df = df[list(key_mapper.values())]\n",
    "\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    return df\n",
    "\n",
    "get_weather_file('./data/shop_1_weather.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
